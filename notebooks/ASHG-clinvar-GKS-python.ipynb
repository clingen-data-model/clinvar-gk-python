{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clinvar_gk_pilot.gcs import (\n",
    "    _local_file_path_for,\n",
    "    download_to_local_file,\n",
    "    already_downloaded,\n",
    ")\n",
    "\n",
    "# variation_blob_uri = \"gs://clingen-public/clinvar-gk-pilot/2024-04-07/dev/clinvar-variation-20240407.json.gz\"\n",
    "# scv_blob_uri = (\n",
    "#     \"gs://clingen-public/clinvar-gk-pilot/2024-04-07/dev/clinvar-scvs-20240407.json.gz\"\n",
    "# )\n",
    "\n",
    "catvar_blob_uri = (\n",
    "    \"gs://clinvar-gk-pilot/2024-04-07/dev/combined-catvar_output.ndjson.gz\"\n",
    ")\n",
    "scv_blob_uri = \"gs://clinvar-gk-pilot/2024-04-07/dev/combined-scv_output.ndjson.gz\"\n",
    "\n",
    "catvar_file = \"combined-catvar_output.ndjson.gz\"\n",
    "\n",
    "\n",
    "variation_local_file_path = _local_file_path_for(catvar_blob_uri)\n",
    "if not already_downloaded(catvar_blob_uri):\n",
    "    print(f\"Downloading {catvar_blob_uri} to {variation_local_file_path}\")\n",
    "    dl_variation_local_file_path = download_to_local_file(catvar_blob_uri)\n",
    "    assert dl_variation_local_file_path == variation_local_file_path\n",
    "\n",
    "scv_local_file_path = _local_file_path_for(scv_blob_uri)\n",
    "if not already_downloaded(scv_blob_uri):\n",
    "    print(f\"Downloading {scv_blob_uri} to {scv_local_file_path}\")\n",
    "    dl_scv_local_file_path = download_to_local_file(scv_blob_uri)\n",
    "    assert dl_scv_local_file_path == scv_local_file_path\n",
    "\n",
    "catvar_file = variation_local_file_path\n",
    "scv_file = scv_local_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our ClinVar datasets are available as NDJSON files. There is a variation file and an SCV file. The records of the variation file are CategoricalVariation objects, and the records of the SCV file are `VariationPathogenicity` (sub-class of `Statement`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "################################\n",
    "# Query the SCV file for a VRS ID using vanilla Python\n",
    "#\n",
    "# - for a given ClinVar Variation ID, find the corresponding GA4GH CatVar record in the CatVar\n",
    "#   file and find the SCVs which reference that variant in the SCV file\n",
    "#\n",
    "#   (NOTE: the SCV file also contains the full CatVar definition in the \"variation\" field, but\n",
    "#    this example illustrates how to query across both files, since the SCV file can be\n",
    "#    relationally normalized to extract that redundant entity and refer to the variant\n",
    "#    by the CatVar ID as a foreign key)\n",
    "#\n",
    "# - print the SCV interpretations for that variant\n",
    "#\n",
    "################################\n",
    "################################\n",
    "# Inputs\n",
    "\n",
    "################################\n",
    "# A CanonicalAllele\n",
    "## For searching based on the GKS Categorical Variation (CatVrs) ID\n",
    "clinvar_id = \"563765\"\n",
    "## For searching based on the GA4GH VRS Variation ID\n",
    "vrs_id = \"ga4gh:VA.hf_va4AnlG99NuOjtaXJzh_XvszWWOO9\"\n",
    "\n",
    "\n",
    "################################\n",
    "# A CategoricalCnv\n",
    "## For searching based on the GKS Categorical Variation (CatVrs) ID\n",
    "clinvar_id = \"599353\"\n",
    "## For searching based on the GA4GH VRS Variation ID\n",
    "vrs_id = \"ga4gh:CX.5iqyOA4L5njh5FpymTPcwQ8oHTilQFmo\"  # GRCh38 member\n",
    "\n",
    "\n",
    "catvar_file = \"combined-catvar_output.ndjson.gz\"\n",
    "scv_file = \"combined-scv_output.ndjson.gz\"\n",
    "################################\n",
    "assert os.path.exists(catvar_file)\n",
    "assert os.path.exists(scv_file)\n",
    "catvar_id = f\"clinvar:{clinvar_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Query the SCV file for the matching VRS ID\n",
    "################################\n",
    "\n",
    "\n",
    "def query_scvs_by_vrs_id(vrs_id: str, scv_file: str):\n",
    "    scvs = []\n",
    "    catvars = []\n",
    "    with gzip.open(scv_file, \"rt\") as f:\n",
    "        for line in f:\n",
    "            record = json.loads(line)\n",
    "            variation = record[\"variation\"]\n",
    "            processing_errors = [\n",
    "                e\n",
    "                for e in variation.get(\"extensions\", [])\n",
    "                if e[\"name\"] == \"vrs processing errors\"\n",
    "            ]\n",
    "            if len(processing_errors) > 0:\n",
    "                # print(f\"Skipping SCV record with VRS processing errors: {line}\")\n",
    "                continue\n",
    "\n",
    "            match variation[\"type\"]:\n",
    "                case \"CategoricalCnv\":\n",
    "                    if \"members\" not in variation:\n",
    "                        # Unsupported?\n",
    "                        # e.g. \"clinvar:1878325\"\n",
    "                        # \"NC_000018.9:g.(48556994_48573289)_48573471dup\"\n",
    "                        # raise ValueError(f\"CategoricalCnv missing members field: {line}\")\n",
    "                        continue\n",
    "                    members = variation[\"members\"]\n",
    "                    member_vrs_ids = [m[\"id\"] for m in members]\n",
    "                    if vrs_id in member_vrs_ids:\n",
    "                        scvs.append(record)\n",
    "\n",
    "                case \"CanonicalAllele\":\n",
    "                    if \"definingContext\" not in variation:\n",
    "                        # Unsupported allele type?\n",
    "                        # e.g. clinvar:215984\n",
    "                        # \"NM_000251.2(MSH2):c.212-?_366+?dup\"\n",
    "                        # raise ValueError(f\"CanonicalAllele missing definingContext field: {line}\")\n",
    "                        continue\n",
    "                    if variation[\"definingContext\"][\"id\"] == vrs_id:\n",
    "                        scvs.append(record)\n",
    "                case \"DescribedVariation\":\n",
    "                    # not an error in processing, but does not have any VRS IDs\n",
    "                    continue\n",
    "                    # raise ValueError(f\"DescribedVariation not yet implemented: {line}\")\n",
    "                case _:\n",
    "                    raise ValueError(f\"Unexpected variation type: {variation['type']}\")\n",
    "    return scvs\n",
    "\n",
    "\n",
    "scvs = query_scvs_by_vrs_id(vrs_id, scv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCV: SCV000864190.1 \n",
      "  Classification: Likely pathogenic\n",
      "  Condition: Squalene synthase deficiency\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for scv in scvs:\n",
    "    classification = scv[\"classification\"][\"label\"]\n",
    "    condition = scv[\"condition\"][\"label\"]\n",
    "    print(f\"SCV: {scv['id']} \")\n",
    "    print(f\"  Classification: {classification}\")\n",
    "    print(f\"  Condition: {condition}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# load the SCV ndjson into a sqlite database with a few indexes on the scv, catvar, and vrs IDs\n",
    "################################\n",
    "# # sqlite schema:\n",
    "# # scv_id: str (index)\n",
    "# # catvar_id: str (index)\n",
    "# # vrs_id: str (index) # Can have multiple records if a record has multiple defining VRS IDs\n",
    "# # value: the blob of the SCV record gziped and as bytes\n",
    "\n",
    "# import sqlite3\n",
    "\n",
    "# db_name = \"clinvar.db\"\n",
    "# conn = sqlite3.connect(db_name)\n",
    "\n",
    "# # Create the schema and the indexes on columns\n",
    "# c = conn.cursor()\n",
    "# c.execute(\n",
    "#     \"\"\"\n",
    "#     CREATE TABLE IF NOT EXISTS scv (\n",
    "#         scv_id TEXT,\n",
    "#         catvar_id TEXT,\n",
    "#         vrs_id TEXT,\n",
    "#         value BLOB,\n",
    "#     )\n",
    "#     \"\"\"\n",
    "# )\n",
    "# c.execute(\"CREATE INDEX IF NOT EXISTS scv_id_index ON scv (scv_id)\")\n",
    "# c.execute(\"CREATE INDEX IF NOT EXISTS catvar_id_index ON scv (catvar_id)\")\n",
    "# c.execute(\"CREATE INDEX IF NOT EXISTS vrs_id_index ON scv (vrs_id)\")\n",
    "# # Create a uniqueness constraint so these cannot be duplicated\n",
    "# c.execute(\n",
    "#     \"CREATE UNIQUE INDEX IF NOT EXISTS scv_catvar_vrs_id_index ON scv (scv_id, catvar_id, vrs_id)\"\n",
    "# )\n",
    "# conn.commit()\n",
    "\n",
    "# with gzip.open(scv_file, \"rt\") as f:\n",
    "#     for line in f:\n",
    "#         record = json.loads(line)\n",
    "\n",
    "#         variation = record[\"variation\"]\n",
    "#         processing_errors = [\n",
    "#             e\n",
    "#             for e in variation.get(\"extensions\", [])\n",
    "#             if e[\"name\"] == \"vrs processing errors\"\n",
    "#         ]\n",
    "#         if len(processing_errors) > 0:\n",
    "#             # print(\n",
    "#             #     f\"Skipping SCV record with VRS processing errors: {json.dumps(record)}\"\n",
    "#             # )\n",
    "#             continue\n",
    "\n",
    "#         match variation[\"type\"]:\n",
    "#             case \"CategoricalCnv\":\n",
    "#                 if \"members\" not in variation:\n",
    "#                     # Unsupported?\n",
    "#                     # e.g. \"clinvar:1878325\"\n",
    "#                     # \"NC_000018.9:g.(48556994_48573289)_48573471dup\"\n",
    "#                     # raise ValueError(\n",
    "#                     #     f\"CategoricalCnv missing members field: {json.dumps(record)}\"\n",
    "#                     # )\n",
    "#                     continue\n",
    "#                 members = variation[\"members\"]\n",
    "#                 member_vrs_ids = [m[\"id\"] for m in members]\n",
    "#                 if vrs_id in member_vrs_ids:\n",
    "#                     scvs.append(record)\n",
    "\n",
    "#             case \"CanonicalAllele\":\n",
    "#                 if \"definingContext\" not in variation:\n",
    "#                     # Unsupported allele type?\n",
    "#                     # e.g. clinvar:215984\n",
    "#                     # \"NM_000251.2(MSH2):c.212-?_366+?dup\"\n",
    "#                     # raise ValueError(\n",
    "#                     #     f\"CanonicalAllele missing definingContext field: {json.dumps(record)}\"\n",
    "#                     # )\n",
    "#                     continue\n",
    "#                 if variation[\"definingContext\"][\"id\"] == vrs_id:\n",
    "#                     scvs.append(record)\n",
    "#             case \"DescribedVariation\":\n",
    "#                 # do not have any VRS IDs\n",
    "#                 continue\n",
    "#                 # raise ValueError(\n",
    "#                 #     f\"DescribedVariation not yet implemented: {json.dumps(record)}\"\n",
    "#                 # )\n",
    "#             case _:\n",
    "#                 raise ValueError(f\"Unexpected variation type: {variation['type']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "While these can be read with vanilla python by iterating lines and parsing each as JSON, there are also libraries which can make querying the files simpler and potentially more performant.\n",
    "\n",
    "One option is DuckDB. DuckDB achieves fast speeds and low memory utilization by memory mapping files and dropping rows from memory that don't match filter criteria. It also has the benefit of being able to query GZIP-compressed NDJSON files directly, so disk storage stays minimal, and presenting a SQL interface to the data, with full support of nested structs so we can access fields from nested JSON objects without manipulating the files. Another benefit is that it gracefully handles heterogeneous record schemas, automatically nulling values that don't exist in particular rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option to query the NDJSON files is the Polars library for Python.\n",
    "\n",
    "This library is similar to Pandas, but it is written in Rust, and it supports lazily querying files without loading all contents into memory.\n",
    "\n",
    "To read a whole NDJSON file, use `pandas.read_ndjson`. To read it lazily and only load into a dataframe the fields of rows that match applied filters, use `pandas.scan_ndjson` (as we do below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "schema = pl.Schema({\"id\": pl.Utf8, \"definingContext\": pl.Struct({\"id\": pl.Utf8})})\n",
    "\n",
    "# Load the whole file into memory.\n",
    "# NOT RECOMMENDED unless you have a very large amount of memory.\n",
    "# Memory requirements include the data itself plus the overhead of the Python and Polars data structures.\n",
    "# import gzip\n",
    "# catvar_file = \"combined-catvar_output.ndjson.gz\"\n",
    "# with gzip.open(catvar_file, \"rb\") as f:\n",
    "#     df = pl.read_ndjson(f, schema=schema)\n",
    "\n",
    "# Load file lazily. Recommended for large files.\n",
    "catvar_file = \"combined-catvar_output.ndjson\"\n",
    "catvar_df = pl.scan_ndjson(\n",
    "    catvar_file,\n",
    "    schema=schema,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(pl.col(\"id\") == \"clinvar:209226\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scv_file = \"combined-scv_output.ndjson\"\n",
    "# scv_schema = pl.Schema(\n",
    "scv_df = pl.scan_ndjson(scv_file)\n",
    "scv_df.head().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SCV000244507.1', {'digest': 'iTe7Ew7If4vdPnhfcT2qXQQY-tNu7tcF', 'expressions': [{'syntax': 'spdi', 'value': 'NC_000017.11:43041892:A:T'}, {'syntax': 'hgvs.g', 'value': 'NC_000017.11:g.43041893A>T'}, {'syntax': 'gnomad', 'value': '17-43041893-A-T'}], 'extensions': [{'name': 'clinvar vcf', 'value': '\"17-43041893-A-T\"'}, {'name': 'clinvar hgvs type', 'value': '\"genomic, top-level\"'}], 'id': 'ga4gh:VA.iTe7Ew7If4vdPnhfcT2qXQQY-tNu7tcF', 'label': 'NC_000017.11:43041892:A:T', 'location': {'digest': 'zdH_x64Ewl4jnJSjPQrb9ENIPb8GZOG-', 'end': '43041893', 'id': 'ga4gh:SL.zdH_x64Ewl4jnJSjPQrb9ENIPb8GZOG-', 'sequenceReference': {'extensions': [{'name': 'assembly', 'value': 'GRCh38'}, {'name': 'chromosome', 'value': '17'}], 'id': 'NC_000017.11', 'refgetAccession': 'SQ.dLZ15tNO1Ur0IcGjwc3Sdi_0A6Yf4zm7', 'residueAlphabet': 'na', 'type': 'SequenceReference'}, 'start': '43041892', 'type': 'SequenceLocation'}, 'state': '{\"sequence\":\"T\",\"type\":\"LiteralSequenceExpression\"}', 'type': 'Allele', 'copies': None, 'copyChange': None}, {'id': 'SCV000244507.1', 'member': {'digest': 'iTe7Ew7If4vdPnhfcT2qXQQY-tNu7tcF', 'expressions': [{'syntax': 'spdi', 'value': 'NC_000017.11:43041892:A:T'}, {'syntax': 'hgvs.g', 'value': 'NC_000017.11:g.43041893A>T'}, {'syntax': 'gnomad', 'value': '17-43041893-A-T'}], 'extensions': [{'name': 'clinvar vcf', 'value': '\"17-43041893-A-T\"'}, {'name': 'clinvar hgvs type', 'value': '\"genomic, top-level\"'}], 'id': 'ga4gh:VA.iTe7Ew7If4vdPnhfcT2qXQQY-tNu7tcF', 'label': 'NC_000017.11:43041892:A:T', 'location': {'digest': 'zdH_x64Ewl4jnJSjPQrb9ENIPb8GZOG-', 'end': '43041893', 'id': 'ga4gh:SL.zdH_x64Ewl4jnJSjPQrb9ENIPb8GZOG-', 'sequenceReference': {'extensions': [{'name': 'assembly', 'value': 'GRCh38'}, {'name': 'chromosome', 'value': '17'}], 'id': 'NC_000017.11', 'refgetAccession': 'SQ.dLZ15tNO1Ur0IcGjwc3Sdi_0A6Yf4zm7', 'residueAlphabet': 'na', 'type': 'SequenceReference'}, 'start': '43041892', 'type': 'SequenceLocation'}, 'state': '{\"sequence\":\"T\",\"type\":\"LiteralSequenceExpression\"}', 'type': 'Allele', 'copies': None, 'copyChange': None}, 'classification': {'code': 'cg000001', 'label': 'Benign', 'system': 'https://dataexchange.clinicalgenome.org/codes/'}, 'condition': {'id': 'clinvarTrait:4711', 'label': 'Breast-ovarian cancer, familial, susceptibility to, 1', 'mappings': [{'coding': {'code': 'C2676676', 'system': 'https://www.ncbi.nlm.nih.gov/medgen/'}, 'relation': 'exactMatch'}], 'type': 'Disease', 'extensions': None, 'traits': None}, 'contributions': [{'activity': {'code': 'CRO_0000105', 'label': 'submitter role', 'system': 'http://purl.obolibrary.org/obo/'}, 'agent': {'id': 'clinvar.submitter:504863', 'label': 'Evidence-based Network for the Interpretation of Germline Mutant Alleles (ENIGMA)', 'type': 'Agent'}, 'date': datetime.date(2015, 9, 29), 'label': 'Last Updated', 'type': 'Contribution'}, {'activity': {'code': 'CRO_0000105', 'label': 'submitter role', 'system': 'http://purl.obolibrary.org/obo/'}, 'agent': {'id': 'clinvar.submitter:504863', 'label': 'Evidence-based Network for the Interpretation of Germline Mutant Alleles (ENIGMA)', 'type': 'Agent'}, 'date': datetime.date(2015, 9, 29), 'label': 'First in ClinVar', 'type': 'Contribution'}, {'activity': {'code': 'CRO_0000001', 'label': 'author role', 'system': 'http://purl.obolibrary.org/obo/'}, 'agent': {'id': 'clinvar.submitter:504863', 'label': 'Evidence-based Network for the Interpretation of Germline Mutant Alleles (ENIGMA)', 'type': 'Agent'}, 'date': datetime.date(2015, 1, 12), 'label': 'Last Evaluated', 'type': 'Contribution'}], 'direction': 'refutes', 'extensions': [{'name': 'localKey', 'value': 'NM_007294.3:c.*3785T>A|OMIM:604370'}, {'name': 'clinvarMethodCategory', 'value': 'curation'}, {'name': 'submittedClassification', 'value': 'Benign'}, {'name': 'clinvarReviewStatus', 'value': 'reviewed by expert panel'}], 'id_1': 'SCV000244507.1', 'method': {'isReportedIn': {'pmid': None, 'type': 'Document', 'url': 'https://submit.ncbi.nlm.nih.gov/ft/byid/c2ffjci6/enigma_rules_2015-03-26.pdf', 'doi': None}, 'label': 'ENIGMA BRCA1/2 Classification Criteria (2015)', 'type': 'Method'}, 'predicate': 'isCausalFor', 'scv_id': 'SCV000244507', 'scv_ver': 1, 'strength': {'code': 'cg000101', 'label': 'definitive', 'system': 'https://dataexchange.clinicalgenome.org/codes/'}, 'type': 'VariationPathogenicity', 'variation': {'definingContext': {'digest': 'iTe7Ew7If4vdPnhfcT2qXQQY-tNu7tcF', 'expressions': [{'syntax': 'spdi', 'value': 'NC_000017.11:43041892:A:T'}, {'syntax': 'hgvs.g', 'value': 'NC_000017.11:g.43041893A>T'}, {'syntax': 'gnomad', 'value': '17-43041893-A-T'}], 'extensions': [{'name': 'clinvar vcf', 'value': '17-43041893-A-T'}, {'name': 'clinvar hgvs type', 'value': 'genomic, top-level'}], 'id': 'ga4gh:VA.iTe7Ew7If4vdPnhfcT2qXQQY-tNu7tcF', 'label': 'NC_000017.11:43041892:A:T', 'location': {'digest': 'zdH_x64Ewl4jnJSjPQrb9ENIPb8GZOG-', 'end': 43041893, 'id': 'ga4gh:SL.zdH_x64Ewl4jnJSjPQrb9ENIPb8GZOG-', 'sequenceReference': {'extensions': [{'name': 'assembly', 'value': 'GRCh38'}, {'name': 'chromosome', 'value': '17'}], 'id': 'NC_000017.11', 'refgetAccession': 'SQ.dLZ15tNO1Ur0IcGjwc3Sdi_0A6Yf4zm7', 'residueAlphabet': 'na', 'type': 'SequenceReference'}, 'start': 43041892, 'type': 'SequenceLocation'}, 'state': {'sequence': 'T', 'type': 'LiteralSequenceExpression', 'length': None, 'repeatSubunitLength': None}, 'type': 'Allele'}, 'extensions': [{'name': 'cytogenetic location', 'value': '17q21.31'}, {'name': 'clinvar variation type', 'value': 'single nucleotide variant'}, {'name': 'clinvar subclass type', 'value': 'SimpleAllele'}], 'id': 'clinvar:209226', 'label': 'NM_007294.3(BRCA1):c.*3785T>A', 'members': [{'digest': 'iTe7Ew7If4vdPnhfcT2qXQQY-tNu7tcF', 'expressions': [{'syntax': 'spdi', 'value': 'NC_000017.11:43041892:A:T'}, {'syntax': 'hgvs.g', 'value': 'NC_000017.11:g.43041893A>T'}, {'syntax': 'gnomad', 'value': '17-43041893-A-T'}], 'extensions': [{'name': 'clinvar vcf', 'value': '\"17-43041893-A-T\"'}, {'name': 'clinvar hgvs type', 'value': '\"genomic, top-level\"'}], 'id': 'ga4gh:VA.iTe7Ew7If4vdPnhfcT2qXQQY-tNu7tcF', 'label': 'NC_000017.11:43041892:A:T', 'location': {'digest': 'zdH_x64Ewl4jnJSjPQrb9ENIPb8GZOG-', 'end': '43041893', 'id': 'ga4gh:SL.zdH_x64Ewl4jnJSjPQrb9ENIPb8GZOG-', 'sequenceReference': {'extensions': [{'name': 'assembly', 'value': 'GRCh38'}, {'name': 'chromosome', 'value': '17'}], 'id': 'NC_000017.11', 'refgetAccession': 'SQ.dLZ15tNO1Ur0IcGjwc3Sdi_0A6Yf4zm7', 'residueAlphabet': 'na', 'type': 'SequenceReference'}, 'start': '43041892', 'type': 'SequenceLocation'}, 'state': '{\"sequence\":\"T\",\"type\":\"LiteralSequenceExpression\"}', 'type': 'Allele', 'copies': None, 'copyChange': None}, {'digest': None, 'expressions': [{'syntax': 'hgvs.g', 'value': 'NC_000017.10:g.41193910A>T'}, {'syntax': 'gnomad', 'value': '17-41193910-A-T'}], 'extensions': [{'name': 'clinvar vcf', 'value': '\"17-41193910-A-T\"'}, {'name': 'clinvar hgvs type', 'value': '\"genomic, top-level\"'}], 'id': 'clinvar:209226-NC_000017.10', 'label': 'NC_000017.10:g.41193910A>T', 'location': {'digest': None, 'end': '41193910', 'id': None, 'sequenceReference': {'extensions': [{'name': 'assembly', 'value': 'GRCh37'}, {'name': 'chromosome', 'value': '17'}], 'id': 'NC_000017.10', 'refgetAccession': None, 'residueAlphabet': 'na', 'type': 'SequenceReference'}, 'start': '41193910', 'type': 'SequenceLocation'}, 'state': None, 'type': 'Allele', 'copies': None, 'copyChange': None}, {'digest': None, 'expressions': [{'syntax': 'hgvs.g', 'value': 'NG_005905.2:g.176091T>A'}], 'extensions': [{'name': 'clinvar hgvs type', 'value': '\"genomic\"'}], 'id': 'clinvar:209226-NG_005905.2', 'label': 'NG_005905.2:g.176091T>A', 'location': {'digest': None, 'end': None, 'id': None, 'sequenceReference': {'extensions': None, 'id': 'NG_005905.2', 'refgetAccession': None, 'residueAlphabet': 'na', 'type': 'SequenceReference'}, 'start': None, 'type': 'SequenceLocation'}, 'state': None, 'type': 'Allele', 'copies': None, 'copyChange': None}, {'digest': None, 'expressions': [{'syntax': 'hgvs.g', 'value': 'LRG_292:g.176091T>A'}], 'extensions': [{'name': 'clinvar hgvs type', 'value': '\"genomic\"'}, {'name': 'pre-processing vrs issue', 'value': '\"sequence for accession not supported by vrs-python release\"'}], 'id': 'clinvar:209226-LRG_292', 'label': 'LRG_292:g.176091T>A', 'location': {'digest': None, 'end': None, 'id': None, 'sequenceReference': {'extensions': None, 'id': 'LRG_292', 'refgetAccession': None, 'residueAlphabet': 'na', 'type': 'SequenceReference'}, 'start': None, 'type': 'SequenceLocation'}, 'state': None, 'type': 'Allele', 'copies': None, 'copyChange': None}, {'digest': None, 'expressions': [{'syntax': 'hgvs.c', 'value': 'LRG_292t1:c.*3785T>A'}], 'extensions': [{'name': 'pre-processing vrs issue', 'value': '\"sequence for accession not supported by vrs-python release\"'}, {'name': 'clinvar hgvs type', 'value': '\"coding\"'}], 'id': 'clinvar:209226-LRG_292t1', 'label': 'LRG_292t1:c.*3785T>A', 'location': {'digest': None, 'end': None, 'id': None, 'sequenceReference': {'extensions': None, 'id': 'LRG_292t1', 'refgetAccession': None, 'residueAlphabet': 'na', 'type': 'SequenceReference'}, 'start': None, 'type': 'SequenceLocation'}, 'state': None, 'type': 'Allele', 'copies': None, 'copyChange': None}], 'type': 'CanonicalAllele', 'mappings': None, 'copies': None, 'location': None, 'copyChange': None}, 'description': 'Class 1 not pathogenic based on frequency >1% in an outbred sampleset. Frequency 0.33 (Asian), 0.87 (African), 0.37 (European), derived from 1000 genomes (2012-04-30).', 'isReportedIn': None, 'qualifiers': None})\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import duckdb\n",
    "\n",
    "scv_file = \"combined-scv_output.ndjson.gz\"\n",
    "vrs_id = \"ga4gh:VA.iTe7Ew7If4vdPnhfcT2qXQQY-tNu7tcF\"\n",
    "# d = duckdb.connect()\n",
    "query = f\"\"\"\n",
    "SELECT id, member, a\n",
    "FROM\n",
    "    (SELECT id, UNNEST(variation.members) AS member, s.*\n",
    "    FROM read_json('combined-scv_output.ndjson.gz', format='newline_delimited', ignore_errors=true) s\n",
    "    ) a\n",
    "WHERE member.id = '{vrs_id}'\n",
    "\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "# AND a.variation.type = 'CategoricalCnv'\n",
    "# WHERE (variation.type = 'CategoricalCnv')\n",
    "# LIMIT 10\n",
    "# AND member.id = '{vrs_id}'\n",
    "\n",
    "results = duckdb.query(query)\n",
    "\n",
    "scv_ids = []\n",
    "while batch := results.fetchmany(100):\n",
    "    for row in batch:\n",
    "        print(row)\n",
    "        scv_ids.append(row[0])\n",
    "\n",
    "scv_ids = [row[0] for row in batch]\n",
    "\n",
    "# with gzip.open(scv_file) as f:\n",
    "#     for line in f:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gzip\n",
    "# import json\n",
    "# import psycopg2\n",
    "# from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "\n",
    "# scv_file = \"combined-scv_output.ndjson.gz\"\n",
    "\n",
    "# # docker volume create clinvar_data\n",
    "# # docker run --name mypostgres -e POSTGRES_PASSWORD=mysecretpassword -d -p 5432:5432 -v clinvar_data:/var/lib/postgresql/data postgres\n",
    "\n",
    "# # Connect to the default database\n",
    "# conn = psycopg2.connect(\n",
    "#     host=\"localhost\", dbname=\"postgres\", user=\"postgres\", password=\"mysecretpassword\"\n",
    "# )\n",
    "# conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "\n",
    "# # Create a new database\n",
    "# cur = conn.cursor()\n",
    "# # cur.execute(\"DROP DATABASE IF EXISTS clinvar\")\n",
    "# db_name = \"clinvar\"\n",
    "# cur.execute(\"SELECT 1 FROM pg_catalog.pg_database WHERE datname = %s\", (db_name,))\n",
    "# db_exists = cur.fetchone()\n",
    "# if not db_exists:\n",
    "#     cur.execute(\"CREATE DATABASE IF NOT EXISTS clinvar\")\n",
    "# cur.close()\n",
    "# conn.close()\n",
    "\n",
    "# # with psycopg2.connect(\n",
    "# #     host=\"localhost\", dbname=\"postgres\", user=\"postgres\", password=\"mysecretpassword\"\n",
    "# # ) as conn:\n",
    "# #     conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "# #     cur = conn.cursor()\n",
    "# #     cur.execute(\"CREATE DATABASE clinvar\")\n",
    "\n",
    "\n",
    "# with psycopg2.connect(\n",
    "#     host=\"localhost\", dbname=\"clinvar\", user=\"postgres\", password=\"mysecretpassword\"\n",
    "# ) as conn:\n",
    "#     cur = conn.cursor()\n",
    "#     cur.execute(\"DROP TABLE IF EXISTS scv\")\n",
    "#     cur.execute(\n",
    "#         \"\"\"\n",
    "#         CREATE TABLE IF NOT EXISTS scv (\n",
    "#             id TEXT PRIMARY KEY,\n",
    "#             value JSONB\n",
    "#         )\n",
    "#         \"\"\"\n",
    "#     )\n",
    "#     cur.execute(\n",
    "#         # Create a GIN index on value.definingContext.id\n",
    "#         \"\"\"\n",
    "#         CREATE INDEX IF NOT EXISTS scv_definingContext_id_index ON scv ((value->'definingContext'->>'id'))\n",
    "#         \"\"\"\n",
    "#     )\n",
    "\n",
    "# import time\n",
    "\n",
    "# start = time.time()\n",
    "# last_printed = start\n",
    "\n",
    "\n",
    "# def file_batch_lines(fileio, batch_size=10000):\n",
    "#     \"\"\"\n",
    "#     Generator function to read a file and yield batches of lines.\n",
    "\n",
    "#     :param file_path: Path to the file to be read.\n",
    "#     :param batch_size: Number of lines per batch.\n",
    "#     \"\"\"\n",
    "#     batch = []\n",
    "#     for line in fileio:\n",
    "#         batch.append(line)\n",
    "#         if len(batch) == batch_size:\n",
    "#             yield batch\n",
    "#             batch = []\n",
    "#     if batch:\n",
    "#         yield batch\n",
    "\n",
    "\n",
    "# with psycopg2.connect(\n",
    "#     host=\"localhost\", dbname=\"clinvar\", user=\"postgres\", password=\"mysecretpassword\"\n",
    "# ) as conn:\n",
    "#     cur = conn.cursor()\n",
    "#     with gzip.open(scv_file, \"rt\") as f:\n",
    "#         idx = 0\n",
    "#         for line_batch in file_batch_lines(f, batch_size=2000):\n",
    "#             # mega SQL string strategy\n",
    "#             records = [json.loads(line) for line in line_batch]\n",
    "#             query_base = \"INSERT INTO scv (id, value) VALUES \"\n",
    "#             values_templ = \",\".join([\"(%s, %s)\"] * len(records))\n",
    "#             values = [(r[\"id\"], line) for r, line in zip(records, line_batch)]\n",
    "#             # flatten values by 1 level\n",
    "#             values = [v for sublist in values for v in sublist]\n",
    "#             query = query_base + values_templ\n",
    "#             cur.execute(query, values)\n",
    "\n",
    "#             # executemany strategy\n",
    "#             # cur.executemany(\n",
    "#             #     \"INSERT INTO scv (id, value) VALUES (%s, %s)\",\n",
    "#             #     [(r[\"id\"], line) for r, line in zip(records, line_batch)],\n",
    "#             # )\n",
    "\n",
    "#             # record = json.loads(line)\n",
    "#             # cur.execute(\n",
    "#             #     \"INSERT INTO scv (id, value) VALUES (%s, %s)\",\n",
    "#             #     (record[\"id\"], json.dumps(record)),\n",
    "#             # )\n",
    "#             idx += len(records)\n",
    "#             if time.time() - last_printed > 10:\n",
    "#                 print(f\"Inserted {idx} records\")\n",
    "#                 last_printed = time.time()\n",
    "#                 cur.execute(\"COMMIT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
